{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Imports"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.model_selection\n",
    "from keras import Sequential\n",
    "from keras.applications import vgg16\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Check for Tensorflow GPU"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "assert tf.config.list_physical_devices('GPU'), \"No GPU device detected\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Constants"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get train and test data from folder.\n",
    "TRAIN_DIRECTORY = Path(\n",
    "    \"data/AFD/AFDï¼ˆAnimal Face Dataset)/face images/Saimiri sciureus\")\n",
    "\n",
    "# Image Specifications\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "NUM_CHANNELS = 3\n",
    "IMAGE_DIMENSIONS = (IMG_HEIGHT, IMG_WIDTH)\n",
    "\n",
    "# Cross Fold Validation\n",
    "TEST_SIZE = 0.1  # 10% reserved for testing\n",
    "NUMBER_FOLDS = 5  # k-fold CV\n",
    "NUMBER_REPEATS = 1  # number of times to repeat k-fold cv\n",
    "\n",
    "# MODEL PARAMETERS\n",
    "BATCH_SIZE = 32  # This is keras default\n",
    "NUM_EPOCHS = 30\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Seed - for reproducibility\n",
    "SEED = 123\n"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def load_image_dataset(directory, img_width, img_height):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for root, _, files in os.walk(directory):\n",
    "        if not files:\n",
    "            continue\n",
    "\n",
    "        root = Path(root)\n",
    "        dir_name = root.name\n",
    "\n",
    "        for file in files:\n",
    "            file_path = root / file\n",
    "            assert file_path.is_file()\n",
    "\n",
    "            img = plt.imread(str(file_path))\n",
    "            if img is not None:\n",
    "                # Add to the dataset\n",
    "                res = cv2.resize(img, dsize=(img_width, img_height))\n",
    "                X.append(res)\n",
    "                y.append(int(dir_name))\n",
    "            else:\n",
    "                # indicate image was skipped\n",
    "                print(\"Unable to read file '{}' Skipping\".format(\n",
    "                    str(file_path.absolute())))\n",
    "\n",
    "    print(len(X))\n",
    "    print(\"First image\")\n",
    "    plt.imshow(X[1])\n",
    "\n",
    "    # Convert to batch along the 0th axis\n",
    "    X = np.stack(X, axis=0)\n",
    "    y = np.stack(y, axis=0)\n",
    "\n",
    "    return X, y\n"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def investigate_class_distribution(y, number_folds):\n",
    "    classes, counts = np.unique(y, return_counts=True)\n",
    "\n",
    "    # TODO - add 1 for false-positives (not a monkey), 1 for previously unseen individuals\n",
    "    number_classes = len(classes)\n",
    "\n",
    "    too_few = np.nonzero(np.where(counts < number_folds, classes, 0))\n",
    "    print(too_few)\n",
    "\n",
    "    plt.hist(y, bins=classes)\n",
    "    plt.xticks(np.arange(min(classes), max(classes) + 1, 1))\n",
    "    plt.ylabel(\"Instances\")\n",
    "    plt.xlabel(\"Class\")\n",
    "    plt.title(\"Class Frequency\")\n",
    "    plt.show()\n",
    "\n",
    "    return number_classes\n"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_stratified_train_test_split(X, y, test_size, seed):\n",
    "    X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
    "        X, y, shuffle=True, test_size=test_size, random_state=seed, stratify=y)\n",
    "\n",
    "    print(\"Train size: \", len(X_train))\n",
    "    print(\"Test size: \", len(X_test))\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Architecture"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class VGGModel:\n",
    "    def __init__(self, epochs, learning_rate, number_classes, img_shape):\n",
    "        self.model = self.make_model(number_classes=number_classes, img_shape=img_shape)\n",
    "        self.hist = None\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    @staticmethod\n",
    "    def make_model(number_classes, img_shape):\n",
    "        # See here for implementation https://keras.io/api/applications/vgg/#vgg16-function\n",
    "        vgg_model = vgg16.VGG16(\n",
    "            include_top=False,\n",
    "            weights=\"imagenet\",\n",
    "            input_shape=img_shape,\n",
    "            pooling='avg',  # Global average pooling applied.\n",
    "        )\n",
    "        # Freeze all layers\n",
    "        vgg_model.trainable = False\n",
    "        fully_connected_output = Sequential()\n",
    "\n",
    "        # Add dense layers to perform prediction\n",
    "        fully_connected_output.add(Flatten())\n",
    "        fully_connected_output.add(Dense(units=4096, activation=\"relu\"))\n",
    "        fully_connected_output.add(Dense(units=4096, activation=\"relu\"))\n",
    "        fully_connected_output.add(\n",
    "            Dense(units=number_classes, activation=\"softmax\"))\n",
    "\n",
    "        # Create final model\n",
    "        return Sequential([vgg_model, fully_connected_output])\n",
    "\n",
    "    def compile(self):\n",
    "        optimizer = Adam(learning_rate=self.learning_rate)\n",
    "\n",
    "        # sparse as Y values are stored as integers (0-42), rather than one-hot encoded (i.e. 3 class, [1,0,0], [0,1,0], [0,0,1])\n",
    "        loss = sparse_categorical_crossentropy\n",
    "\n",
    "        self.model.compile(optimizer=optimizer, loss=loss,\n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "    # Pre-Process Data for VGG\n",
    "    @staticmethod\n",
    "    def pre_process(X_unprocessed):\n",
    "        # is performing in slices\n",
    "        return np.apply_along_axis(func1d=lambda x: vgg16.preprocess_input(x), axis=0, arr=X_unprocessed)\n",
    "\n",
    "    def fit(self, raw_X, raw_y, val_x, val_y):\n",
    "        preprocessed_X = self.pre_process(raw_X)\n",
    "        preprocessed_val_x = self.pre_process(val_x)\n",
    "        self.hist = self.model.fit(\n",
    "            x=preprocessed_X,\n",
    "            y=raw_y,\n",
    "            epochs=self.epochs,\n",
    "            verbose=True,\n",
    "            validation_data=(preprocessed_val_x, val_y))\n",
    "\n",
    "    def evaluate(self, X_eval, y_eval):\n",
    "        preprocessed_X = self.pre_process(X_eval)\n",
    "        return self.model.evaluate(preprocessed_X, y_eval)\n",
    "\n",
    "    def predict(self, X_pred):\n",
    "        preprocessed_X = self.pre_process(X_pred)\n",
    "        return self.model.predict(X_pred)\n",
    "\n",
    "    def plot_results(self):\n",
    "        self.plot_accuracy()\n",
    "        self.plot_loss()\n",
    "\n",
    "    def plot_accuracy(self):\n",
    "        plt.plot(self.hist.history['accuracy'])\n",
    "        plt.title(\"Model Accuracy\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.show()\n",
    "\n",
    "    def plot_loss(self):\n",
    "        plt.plot(self.hist.history['loss'])\n",
    "        plt.title(\"Model Loss\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.show()\n"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def train_and_eval_model(wrapped_keras_model: VGGModel, X_train, y_train, X_val, y_val: np.ndarray):\n",
    "    \"\"\"\n",
    "    Trains and Evaluates the input wrapped Keras model.\n",
    "    :param wrapped_keras_model: The model object should implement the compile, fit, and\n",
    "    evaluate methods.\n",
    "    :param X_train: The training dataset to be used, as a 4d np array\n",
    "    :param y_train: The training dataset labels to be used. Should be sparsely encoded.\n",
    "    :param X_val: The validation dataset to be used, as a 4d np array\n",
    "    :param y_val: The validation dataset labels to be used. Should be sparsely encoded.\n",
    "    :return: The score (typically loss & accuracy) of the model of the fitted model on the validation dataset\n",
    "    \"\"\"\n",
    "    wrapped_keras_model.compile()\n",
    "\n",
    "    # Could split into batches here.\n",
    "    print(\"Fitting Model:\")\n",
    "    wrapped_keras_model.fit(X_train, y_train, X_val, y_val)\n",
    "\n",
    "    print()\n",
    "    print(\"Evaluating Model\")\n",
    "    wrapped_keras_model_score = wrapped_keras_model.evaluate(X_val, y_val)\n",
    "\n",
    "    print()\n",
    "    print(\"Model Score\")\n",
    "    metric_names = wrapped_keras_model.model.metrics_names\n",
    "    for j in range(len(metric_names)):\n",
    "        print(\n",
    "            \"- {}: {:.2f}\".format(metric_names[j], wrapped_keras_model_score[j]))\n",
    "\n",
    "    wrapped_keras_model.plot_results()\n",
    "\n",
    "    return wrapped_keras_model_score\n"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def repeated_stratified_k_fold(num_repeats, num_folds, seed, X, y, number_classes):\n",
    "    rskf = sklearn.model_selection.RepeatedStratifiedKFold(\n",
    "        n_repeats=num_repeats,\n",
    "        n_splits=num_folds,\n",
    "        random_state=seed,\n",
    "    )\n",
    "\n",
    "    scores = np.zeros(shape=(rskf.get_n_splits(X, y), 2))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(rskf.split(X, y)):\n",
    "        print(\"*** Performing Repeat {}/{} Fold {}/{}***\".format(round(i / (NUMBER_FOLDS + 1)) + 1,\n",
    "                                                                 NUMBER_REPEATS,\n",
    "                                                                 (i + 1) % (NUMBER_FOLDS + 1),\n",
    "                                                                 NUMBER_FOLDS), )\n",
    "        X_train, X_val = X[train_index], X[test_index]\n",
    "        y_train, y_val = y[train_index], y[test_index]\n",
    "\n",
    "        model = VGGModel(epochs=NUM_EPOCHS, number_classes=number_classes,\n",
    "                         img_shape=(IMG_HEIGHT, IMG_WIDTH, NUM_CHANNELS))\n",
    "        score = train_and_eval_model(wrapped_keras_model=model,\n",
    "                                     X_train=X_train,\n",
    "                                     y_train=y_train,\n",
    "                                     X_val=X_val,\n",
    "                                     y_val=y_val)\n",
    "        scores[i, 0] = score[0]\n",
    "        scores[i, 1] = score[1]\n",
    "\n",
    "        print(\"\\n\\n\", end=\"\")\n",
    "\n",
    "    return scores\n"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Train Final Model using All Data and Compare to Test Set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def train_and_evaluate_full_model(X_train, X_test, y_train, y_test, number_classes):\n",
    "    final_model = VGGModel(epochs=NUM_EPOCHS, number_classes=number_classes,\n",
    "                           img_shape=(IMG_HEIGHT, IMG_WIDTH, NUM_CHANNELS))\n",
    "    test_score = train_and_eval_model(wrapped_keras_model=final_model,\n",
    "                                      X_train=X_train,\n",
    "                                      y_train=y_train,\n",
    "                                      X_val=X_test,\n",
    "                                      y_val=y_test)\n",
    "\n",
    "    return final_model, test_score\n"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X, y = load_image_dataset(directory=TRAIN_DIRECTORY,\r\n",
    "                          img_width=IMG_WIDTH, img_height=IMG_HEIGHT)\r\n"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "number_classes = investigate_class_distribution(y=y, number_folds=NUMBER_FOLDS)\r\n"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train, X_test, y_train, y_test = get_stratified_train_test_split(\r\n",
    "    X=X, y=y, test_size=TEST_SIZE, seed=SEED)\r\n"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rskf_scores = repeated_stratified_k_fold(X=X_train, y=y_train,\r\n",
    "                                         number_classes=number_classes,\r\n",
    "                                         num_repeats=NUMBER_REPEATS,\r\n",
    "                                         num_folds=NUMBER_FOLDS,\r\n",
    "                                         seed=SEED)\r\n"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cross_validated_score = np.average(rskf_scores, axis=0)\r\n",
    "\r\n",
    "print(\"Average Loss: {:.2f}\".format(cross_validated_score[0]))\r\n",
    "print(\"Average Accuracy: {:.2f}%\".format(cross_validated_score[1] * 100))\r\n"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Testing Model on Full Dataset:\")\r\n",
    "final_model, final_model_score = train_and_evaluate_full_model(X_train=X_train,\r\n",
    "                                                               y_train=y_train,\r\n",
    "                                                               X_test=X_test,\r\n",
    "                                                               y_test=y_test,\r\n",
    "                                                               number_classes=number_classes)\r\n",
    "\r\n",
    "print(\"Full Training Dataset Average Loss: {:.2f}\".format(\r\n",
    "    final_model_score[0]))\r\n",
    "print(\"Full Training Dataset Average Accuracy: {:.2f}%\".format(\r\n",
    "    final_model_score[1] * 100))\r\n"
   ],
   "outputs": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-e8a58dcf",
   "language": "python",
   "display_name": "PyCharm (Compsci 760 - Animal Indentification)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "interpreter": {
   "hash": "308deec42ab0feb8541abaf49f03ee6823cd3b53ac1144ba51ed94aa121850b8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}